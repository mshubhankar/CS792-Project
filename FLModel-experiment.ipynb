{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import syft as sy\n",
    "import copy\n",
    "hook = sy.TorchHook(torch)\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")\n",
    "\n",
    "bob.add_workers([alice, secure_worker])\n",
    "alice.add_workers([bob, secure_worker])\n",
    "secure_worker.add_workers([alice, bob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=np.genfromtxt(\"diabetes.csv\",delimiter=',',skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataframe[:,0:8]\n",
    "Y=dataframe[:,8]\n",
    "Y=Y.reshape(768,1)\n",
    "dtype=torch.float\n",
    "device=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "model=StandardScaler()\n",
    "X=model.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy(X)\n",
    "target = torch.from_numpy(Y)\n",
    "data,target=data.type(torch.FloatTensor),target.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length,data_width=data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_data = data[0:int(data_length/2)].send(bob)\n",
    "bobs_target = target[0:int(data_length/2)].send(bob)\n",
    "\n",
    "alices_data = data[int(data_length/2):].send(alice)\n",
    "alices_target = target[int(data_length/2):].send(alice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class my_network(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(my_network, self).__init__()\n",
    "#         self.fc1=nn.Linear(data_width,500)\n",
    "#         self.fc2=nn.Linear(500,100)\n",
    "#         self.fc3=nn.Linear(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_network, self).__init__()\n",
    "        self.fc1=nn.Linear(data_width,200)\n",
    "        self.activ=nn.ReLU()\n",
    "        self.fc2=nn.Linear(200,100)\n",
    "        self.activ2=nn.ReLU()\n",
    "        self.fc3=nn.Linear(100,1)\n",
    "#         self.activ3=nn.ReLU()\n",
    "    \n",
    "    def forward(self,input_):\n",
    "        a1=self.fc1(input_)\n",
    "        a1=self.activ(a1)\n",
    "        a2=self.fc2(a1)\n",
    "        a2=self.activ2(a2)\n",
    "        y=self.fc3(a2)\n",
    "#         y=self.activ3(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=my_network()\n",
    "loss= torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_model = model.copy().send(bob)\n",
    "alices_model = model.copy().send(alice)\n",
    "\n",
    "bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.001)\n",
    "alices_opt = optim.SGD(params=alices_model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob:tensor(0.3146) Alice:tensor(0.2721)\n",
      "Bob:tensor(0.3133) Alice:tensor(0.2712)\n",
      "Bob:tensor(0.3121) Alice:tensor(0.2704)\n",
      "Bob:tensor(0.3109) Alice:tensor(0.2696)\n",
      "Bob:tensor(0.3097) Alice:tensor(0.2689)\n",
      "Bob:tensor(0.3085) Alice:tensor(0.2681)\n",
      "Bob:tensor(0.3073) Alice:tensor(0.2673)\n",
      "Bob:tensor(0.3061) Alice:tensor(0.2666)\n",
      "Bob:tensor(0.3050) Alice:tensor(0.2658)\n",
      "Bob:tensor(0.3038) Alice:tensor(0.2651)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    # Train Bob's Model\n",
    "    bobs_opt.zero_grad()\n",
    "    bobs_pred = bobs_model(bobs_data)\n",
    "    bobs_loss = loss(bobs_pred,bobs_target)\n",
    "    bobs_loss.backward()\n",
    "\n",
    "    bobs_opt.step()\n",
    "    bobs_loss = bobs_loss.get().data\n",
    "\n",
    "    # Train Alice's Model\n",
    "    alices_opt.zero_grad()\n",
    "    alices_pred = alices_model(alices_data)\n",
    "    alices_loss = loss(alices_pred,alices_target)\n",
    "    alices_loss.backward()\n",
    "\n",
    "    alices_opt.step()\n",
    "    alices_loss = alices_loss.get().data\n",
    "    \n",
    "    print(\"Bob:\" + str(bobs_loss) + \" Alice:\" + str(alices_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "worker_iters = 200\n",
    "\n",
    "for a_iter in range(iterations):\n",
    "    \n",
    "    bobs_model = model.copy().send(bob)\n",
    "    alices_model = model.copy().send(alice)\n",
    "\n",
    "    bobs_opt = optim.Adam(params=bobs_model.parameters(),lr=0.01)\n",
    "    alices_opt = optim.Adam(params=alices_model.parameters(),lr=0.01)\n",
    "\n",
    "    for wi in range(worker_iters):\n",
    "\n",
    "        # Train Bob's Model\n",
    "        bobs_opt.zero_grad()\n",
    "#         bobs_w1=bobs_model.fc1(bobs_data)\n",
    "#         bobs_w2=bobs_model.fc2(bobs_w1)\n",
    "#         bobs_pred=bobs_model.fc3(bobs_w2)\n",
    "#         bobs_pred=bobs_model.fc3(bobs_w2)\n",
    "#         bobs_w1=bobs_model.fc1(bobs_data)\n",
    "#         bobs_w1=bobs_model.activ1(bobs_w1)\n",
    "#         bobs_pred=bobs_model.fc2(bobs_w1)\n",
    "#         bobs_pred=bobs_model.softmax(bobs_pred)\n",
    "        bobs_pred = bobs_model.forward(bobs_data)\n",
    "        bobs_loss = loss(bobs_pred,bobs_target)\n",
    "        bobs_loss.backward()        \n",
    "        bobs_opt.step()\n",
    "#         bobs_opt.step(bobs_data.shape[0])\n",
    "        bobs_loss = bobs_loss.get().data\n",
    "\n",
    "        # Train Alice's Model\n",
    "        alices_opt.zero_grad()\n",
    "#         alices_w1=F.sigmoid(alices_model.fc1(alices_data))\n",
    "#         alices_w2=F.sigmoid(alices_model.fc2(alices_w1))\n",
    "#         alices_pred=F.softmax(alices_model.fc3(alices_w2))\n",
    "#         alices_w1=alices_model.fc1(alices_data)\n",
    "#         alices_w1=alices_model.activ1(alices_w1)\n",
    "#         alices_pred=alices_model.fc2(alices_w1)\n",
    "#         alices_pred=alices_model.softmax(alices_pred)\n",
    "        alices_pred = alices_model.forward(alices_data)\n",
    "        alices_loss = loss(alices_pred,alices_target)\n",
    "        alices_loss.backward()\n",
    "        alices_opt.step()\n",
    "#         alices_opt.step(alices_data.shape[0])\n",
    "        alices_loss = alices_loss.get().data\n",
    "#         print(\"Bob:\" + str(bobs_loss) + \" Alice:\" + str(alices_loss))\n",
    "    \n",
    "    alices_model.move(secure_worker)\n",
    "    bobs_model.move(secure_worker)\n",
    "    \n",
    "    model.fc1.weight.data.set_(((alices_model.fc1.weight.data + bobs_model.fc1.weight.data) / 2).get())\n",
    "    model.fc1.bias.data.set_(((alices_model.fc1.bias.data + bobs_model.fc1.bias.data) / 2).get())\n",
    "    model.fc2.weight.data.set_(((alices_model.fc2.weight.data + bobs_model.fc2.weight.data) / 2).get())\n",
    "    model.fc2.bias.data.set_(((alices_model.fc2.bias.data + bobs_model.fc2.bias.data) / 2).get())\n",
    "    model.fc3.weight.data.set_(((alices_model.fc3.weight.data + bobs_model.fc3.weight.data) / 2).get())\n",
    "    model.fc3.bias.data.set_(((alices_model.fc3.bias.data + bobs_model.fc3.bias.data) / 2).get())\n",
    "    \n",
    "    print(\"Bob:\" + str(bobs_loss) + \" Alice:\" + str(alices_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_pred = bobs_model(bobs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_loss = loss(bobs_pred,bobs_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev=(bobs_model.fc1.weight.data).clone().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_loss.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "after=(bobs_model.fc1.weight.data).clone().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0005)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(prev-after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-8.6007e-03, -7.4330e-04,  3.7530e-03,  1.0351e-03,  5.9490e-03,\n",
       "         2.5547e-04,  3.7711e-03, -1.0140e-02,  2.1963e-03, -1.9414e-03,\n",
       "         2.2193e-03,  7.1897e-04, -1.2450e-03,  6.9786e-04,  5.3132e-04,\n",
       "        -7.3041e-03, -1.1606e-03, -8.4972e-03,  1.7780e-03,  1.3816e-03,\n",
       "        -2.6396e-03,  7.7571e-04,  6.5324e-04, -5.5166e-03,  1.2163e-03,\n",
       "         2.5656e-03,  2.5129e-03,  1.7607e-03, -3.5983e-03,  3.1386e-04,\n",
       "         5.4849e-03,  1.5737e-03, -6.3848e-04, -1.1651e-03, -4.8420e-03,\n",
       "        -8.7499e-03, -8.3866e-03, -1.8201e-03, -1.5377e-03, -6.5627e-03,\n",
       "         6.2573e-03, -6.9072e-04, -2.9139e-03, -5.1051e-03, -4.7599e-03,\n",
       "        -3.1543e-03,  1.4664e-04,  1.0161e-03,  3.3814e-03,  1.8423e-03,\n",
       "         2.6983e-03, -3.5660e-03, -6.1779e-05,  5.5516e-03,  3.4894e-03,\n",
       "         9.2809e-03, -4.2183e-03,  6.9037e-03,  2.3915e-03,  1.9225e-03,\n",
       "         4.4367e-04,  6.4051e-04, -1.5056e-03, -8.4270e-03, -2.1535e-03,\n",
       "         1.4576e-03, -2.0714e-03,  1.8619e-04,  3.1110e-04,  1.2869e-04,\n",
       "        -9.8709e-04, -2.3780e-03, -1.1951e-04, -2.0953e-03,  3.2491e-03,\n",
       "        -1.9994e-03, -9.5635e-04, -1.0330e-03, -1.7374e-04,  1.2899e-03,\n",
       "         4.3962e-03, -3.1370e-03, -1.4817e-03,  6.5099e-03, -4.8637e-03,\n",
       "        -2.7353e-03, -3.4916e-03,  9.3052e-04,  3.8580e-03,  2.6164e-03,\n",
       "        -3.5442e-03, -4.8390e-04,  3.2142e-03,  8.1265e-03, -1.6817e-03,\n",
       "         5.8845e-04,  4.5245e-03, -1.7443e-03,  3.8336e-04, -4.6220e-03,\n",
       "         2.3124e-03,  3.0336e-04, -3.2800e-03,  2.1496e-03,  1.6321e-03,\n",
       "        -3.8031e-03, -3.8118e-03, -1.8115e-04, -3.1792e-03,  2.5182e-03,\n",
       "        -4.4498e-03, -4.4244e-03, -3.4450e-03, -4.5792e-04, -3.9656e-03,\n",
       "        -4.1648e-04, -3.3586e-04, -4.1414e-03, -2.2993e-04, -1.4745e-03,\n",
       "        -7.1951e-03, -7.6413e-04,  6.6193e-03,  2.0566e-03, -3.1892e-03,\n",
       "        -7.4211e-03,  1.9459e-03, -5.6633e-03,  6.9205e-04, -1.8602e-03,\n",
       "         7.2378e-03, -1.1230e-03,  3.0151e-03, -1.0810e-03, -1.2070e-03,\n",
       "        -2.9570e-04,  1.6607e-03, -1.4298e-03,  6.4669e-03, -9.3056e-03,\n",
       "        -1.6443e-03,  5.9643e-04, -5.9696e-04, -2.7656e-03, -7.7000e-04,\n",
       "         8.5785e-04, -1.5859e-03,  7.6464e-05,  7.1090e-03,  1.2788e-03,\n",
       "         2.8626e-04,  1.5349e-03,  2.6323e-04,  1.2082e-03, -1.0522e-03,\n",
       "        -6.4489e-03, -4.8535e-03, -2.7293e-03, -1.8949e-03, -3.1176e-03,\n",
       "         2.5263e-03,  7.5807e-03,  2.4581e-03, -2.0871e-03, -3.0525e-03,\n",
       "        -9.1216e-04, -9.9222e-05,  1.0113e-03,  3.0796e-04, -3.0779e-03,\n",
       "         2.4322e-03, -3.9909e-03,  1.6889e-03,  4.5418e-03,  6.8123e-05,\n",
       "        -4.3503e-03,  5.5132e-03, -8.4991e-03, -7.4420e-03,  4.2806e-03,\n",
       "        -9.3569e-04, -8.0409e-04, -7.1613e-03, -2.4065e-03,  2.1136e-03,\n",
       "         4.6784e-04,  7.4401e-04, -5.3897e-03,  1.9685e-03, -4.0387e-03,\n",
       "         1.0691e-03, -5.1389e-03,  1.8032e-03,  5.3175e-03,  4.6322e-03,\n",
       "         1.3488e-03, -8.2203e-04, -3.9382e-03, -1.5055e-03, -5.5538e-03])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bobs_model.parameters())[1].grad.clone().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
